{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hidden layer 없는 Simple Logitstic Regression model - 1 layer\n",
    "\n",
    "<img src=\"LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**알고리즘의 수학적 표현**:\n",
    "\n",
    "한개의 data (사진 한장) $x^{(i)}$ 에 대하여 :\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "cost 는 모든 training data 의 개별 loss 를 합하여 계산 :\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "<출처> Andrew Ng. - Neural Network and Deep Learning (Coursera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lr_utils import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 64, 64, 3)\n",
      "(50, 64, 64, 3)\n",
      "(1, 209)\n",
      "(1, 50)\n",
      "[b'non-cat' b'cat']\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1 이므로 cat 사진 입니다.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of picture\n",
    "index = 25\n",
    "plt.imshow(X_train[index])\n",
    "print(\"y = \" + str(y_train[0, index]) + \" 이므로 \" + \n",
    "                  classes[y_train[0, index]].decode(\"utf-8\") + \" 사진 입니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "64 x 64 x 3 = 12,288 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209, 12288)\n",
      "(209,)\n",
      "(50, 12288)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "# Flatten image\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], 64*64*3) / 255.\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], 64*64*3) / 255.\n",
    "\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "print(X_train_flatten.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test_flatten.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1, input_shape=(12288,)))\n",
    "model.add(layers.Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 1)                 12289     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 12,289\n",
      "Trainable params: 12,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 209 samples, validate on 50 samples\n",
      "Epoch 1/200\n",
      "209/209 [==============================] - 0s 1ms/sample - loss: 1.0478 - acc: 0.5215 - val_loss: 1.4306 - val_acc: 0.3400\n",
      "Epoch 2/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.8576 - acc: 0.6603 - val_loss: 0.5849 - val_acc: 0.7200\n",
      "Epoch 3/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.6264 - acc: 0.6794 - val_loss: 0.6806 - val_acc: 0.5600\n",
      "Epoch 4/200\n",
      "209/209 [==============================] - 0s 288us/sample - loss: 0.5694 - acc: 0.7225 - val_loss: 0.6497 - val_acc: 0.6200\n",
      "Epoch 5/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.5473 - acc: 0.7177 - val_loss: 0.6589 - val_acc: 0.5800\n",
      "Epoch 6/200\n",
      "209/209 [==============================] - 0s 321us/sample - loss: 0.5490 - acc: 0.7416 - val_loss: 0.9112 - val_acc: 0.3800\n",
      "Epoch 7/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.5147 - acc: 0.7799 - val_loss: 0.5560 - val_acc: 0.7800\n",
      "Epoch 8/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.5238 - acc: 0.7273 - val_loss: 0.6647 - val_acc: 0.5400\n",
      "Epoch 9/200\n",
      "209/209 [==============================] - 0s 249us/sample - loss: 0.5050 - acc: 0.7464 - val_loss: 0.5221 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.5087 - acc: 0.7464 - val_loss: 0.5647 - val_acc: 0.6800\n",
      "Epoch 11/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.4604 - acc: 0.8134 - val_loss: 0.9475 - val_acc: 0.3600\n",
      "Epoch 12/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.4377 - acc: 0.8182 - val_loss: 0.5202 - val_acc: 0.8000\n",
      "Epoch 13/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.4398 - acc: 0.8038 - val_loss: 0.6943 - val_acc: 0.6000\n",
      "Epoch 14/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.4134 - acc: 0.8469 - val_loss: 0.8042 - val_acc: 0.4600\n",
      "Epoch 15/200\n",
      "209/209 [==============================] - 0s 259us/sample - loss: 0.4268 - acc: 0.8086 - val_loss: 0.8885 - val_acc: 0.3800\n",
      "Epoch 16/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.4057 - acc: 0.8373 - val_loss: 0.5690 - val_acc: 0.7200\n",
      "Epoch 17/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.3898 - acc: 0.8517 - val_loss: 0.6055 - val_acc: 0.6800\n",
      "Epoch 18/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.3731 - acc: 0.8565 - val_loss: 0.5157 - val_acc: 0.8200\n",
      "Epoch 19/200\n",
      "209/209 [==============================] - 0s 269us/sample - loss: 0.4106 - acc: 0.8325 - val_loss: 0.5113 - val_acc: 0.8400\n",
      "Epoch 20/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.4330 - acc: 0.7990 - val_loss: 0.6706 - val_acc: 0.6400\n",
      "Epoch 21/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.3948 - acc: 0.8230 - val_loss: 1.1514 - val_acc: 0.3600\n",
      "Epoch 22/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.4377 - acc: 0.8038 - val_loss: 0.8957 - val_acc: 0.4400\n",
      "Epoch 23/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.4516 - acc: 0.7799 - val_loss: 0.5358 - val_acc: 0.7800\n",
      "Epoch 24/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.3506 - acc: 0.8612 - val_loss: 0.5718 - val_acc: 0.7200\n",
      "Epoch 25/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.3426 - acc: 0.8660 - val_loss: 0.5746 - val_acc: 0.7200\n",
      "Epoch 26/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.3344 - acc: 0.8660 - val_loss: 0.9557 - val_acc: 0.4400\n",
      "Epoch 27/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.3549 - acc: 0.8612 - val_loss: 1.1221 - val_acc: 0.3600\n",
      "Epoch 28/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.4469 - acc: 0.7751 - val_loss: 0.7679 - val_acc: 0.6000\n",
      "Epoch 29/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.3974 - acc: 0.8278 - val_loss: 0.5391 - val_acc: 0.8200\n",
      "Epoch 30/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.3882 - acc: 0.7990 - val_loss: 0.5286 - val_acc: 0.8400\n",
      "Epoch 31/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.3678 - acc: 0.8373 - val_loss: 0.6922 - val_acc: 0.7000\n",
      "Epoch 32/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.3348 - acc: 0.8804 - val_loss: 0.9613 - val_acc: 0.4800\n",
      "Epoch 33/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.3080 - acc: 0.8660 - val_loss: 0.8390 - val_acc: 0.6000\n",
      "Epoch 34/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.3042 - acc: 0.8900 - val_loss: 0.6348 - val_acc: 0.7200\n",
      "Epoch 35/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.2663 - acc: 0.9378 - val_loss: 0.7234 - val_acc: 0.6800\n",
      "Epoch 36/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.2955 - acc: 0.8804 - val_loss: 0.5758 - val_acc: 0.7400\n",
      "Epoch 37/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.2822 - acc: 0.8995 - val_loss: 0.5783 - val_acc: 0.7400\n",
      "Epoch 38/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.2853 - acc: 0.8804 - val_loss: 0.7185 - val_acc: 0.6800\n",
      "Epoch 39/200\n",
      "209/209 [==============================] - 0s 326us/sample - loss: 0.3039 - acc: 0.8852 - val_loss: 0.9812 - val_acc: 0.4400\n",
      "Epoch 40/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.3057 - acc: 0.8804 - val_loss: 1.1038 - val_acc: 0.4000\n",
      "Epoch 41/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.3187 - acc: 0.8565 - val_loss: 0.5709 - val_acc: 0.7600\n",
      "Epoch 42/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.2773 - acc: 0.8708 - val_loss: 0.5952 - val_acc: 0.7200\n",
      "Epoch 43/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2538 - acc: 0.9187 - val_loss: 0.7582 - val_acc: 0.6600\n",
      "Epoch 44/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2229 - acc: 0.9713 - val_loss: 0.6382 - val_acc: 0.7400\n",
      "Epoch 45/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2206 - acc: 0.9617 - val_loss: 0.7170 - val_acc: 0.7000\n",
      "Epoch 46/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.2371 - acc: 0.9330 - val_loss: 0.7760 - val_acc: 0.6600\n",
      "Epoch 47/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.2320 - acc: 0.9426 - val_loss: 0.6461 - val_acc: 0.7000\n",
      "Epoch 48/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.2230 - acc: 0.9522 - val_loss: 0.8651 - val_acc: 0.6000\n",
      "Epoch 49/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.2356 - acc: 0.9426 - val_loss: 0.8359 - val_acc: 0.6400\n",
      "Epoch 50/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.2201 - acc: 0.9522 - val_loss: 0.6953 - val_acc: 0.7200\n",
      "Epoch 51/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.2281 - acc: 0.9426 - val_loss: 0.6648 - val_acc: 0.7400\n",
      "Epoch 52/200\n",
      "209/209 [==============================] - 0s 234us/sample - loss: 0.2252 - acc: 0.9522 - val_loss: 0.6421 - val_acc: 0.7200\n",
      "Epoch 53/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.2090 - acc: 0.9665 - val_loss: 0.6761 - val_acc: 0.7200\n",
      "Epoch 54/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1981 - acc: 0.9713 - val_loss: 0.6456 - val_acc: 0.7400\n",
      "Epoch 55/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.2083 - acc: 0.9522 - val_loss: 0.7641 - val_acc: 0.7200\n",
      "Epoch 56/200\n",
      "209/209 [==============================] - 0s 340us/sample - loss: 0.1978 - acc: 0.9665 - val_loss: 0.7876 - val_acc: 0.7200\n",
      "Epoch 57/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.1940 - acc: 0.9665 - val_loss: 0.7705 - val_acc: 0.7200\n",
      "Epoch 58/200\n",
      "209/209 [==============================] - 0s 302us/sample - loss: 0.1900 - acc: 0.9617 - val_loss: 0.7222 - val_acc: 0.7200\n",
      "Epoch 59/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.1831 - acc: 0.9713 - val_loss: 0.6665 - val_acc: 0.7400\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 249us/sample - loss: 0.1895 - acc: 0.9617 - val_loss: 0.7912 - val_acc: 0.7200\n",
      "Epoch 61/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1789 - acc: 0.9713 - val_loss: 0.7054 - val_acc: 0.7200\n",
      "Epoch 62/200\n",
      "209/209 [==============================] - 0s 302us/sample - loss: 0.1792 - acc: 0.9761 - val_loss: 0.9095 - val_acc: 0.6200\n",
      "Epoch 63/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.2085 - acc: 0.9522 - val_loss: 0.9552 - val_acc: 0.5600\n",
      "Epoch 64/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.2054 - acc: 0.9330 - val_loss: 0.7207 - val_acc: 0.7200\n",
      "Epoch 65/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1817 - acc: 0.9761 - val_loss: 0.6321 - val_acc: 0.7200\n",
      "Epoch 66/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1808 - acc: 0.9617 - val_loss: 0.8774 - val_acc: 0.6200\n",
      "Epoch 67/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.1779 - acc: 0.9569 - val_loss: 0.7820 - val_acc: 0.7200\n",
      "Epoch 68/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1612 - acc: 0.9761 - val_loss: 0.6598 - val_acc: 0.7200\n",
      "Epoch 69/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1762 - acc: 0.9665 - val_loss: 0.7242 - val_acc: 0.7400\n",
      "Epoch 70/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1653 - acc: 0.9761 - val_loss: 1.0266 - val_acc: 0.5800\n",
      "Epoch 71/200\n",
      "209/209 [==============================] - 0s 239us/sample - loss: 0.1736 - acc: 0.9617 - val_loss: 0.6827 - val_acc: 0.7200\n",
      "Epoch 72/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.1571 - acc: 0.9809 - val_loss: 0.7827 - val_acc: 0.7000\n",
      "Epoch 73/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1585 - acc: 0.9713 - val_loss: 0.7763 - val_acc: 0.7200\n",
      "Epoch 74/200\n",
      "209/209 [==============================] - 0s 249us/sample - loss: 0.1557 - acc: 0.9761 - val_loss: 0.8846 - val_acc: 0.6600\n",
      "Epoch 75/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1555 - acc: 0.9761 - val_loss: 0.7105 - val_acc: 0.7200\n",
      "Epoch 76/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1496 - acc: 0.9761 - val_loss: 0.7971 - val_acc: 0.7000\n",
      "Epoch 77/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1475 - acc: 0.9713 - val_loss: 0.6871 - val_acc: 0.7200\n",
      "Epoch 78/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1685 - acc: 0.9665 - val_loss: 0.6776 - val_acc: 0.7200\n",
      "Epoch 79/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.2287 - acc: 0.9187 - val_loss: 0.7291 - val_acc: 0.7200\n",
      "Epoch 80/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.2147 - acc: 0.9187 - val_loss: 1.1796 - val_acc: 0.5000\n",
      "Epoch 81/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1945 - acc: 0.9378 - val_loss: 1.0268 - val_acc: 0.5600\n",
      "Epoch 82/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.2013 - acc: 0.9234 - val_loss: 0.7526 - val_acc: 0.7400\n",
      "Epoch 83/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.1504 - acc: 0.9713 - val_loss: 0.7023 - val_acc: 0.7200\n",
      "Epoch 84/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1694 - acc: 0.9426 - val_loss: 0.9876 - val_acc: 0.6000\n",
      "Epoch 85/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1521 - acc: 0.9665 - val_loss: 0.8652 - val_acc: 0.7000\n",
      "Epoch 86/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.1309 - acc: 0.9809 - val_loss: 0.7440 - val_acc: 0.7400\n",
      "Epoch 87/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.1385 - acc: 0.9761 - val_loss: 0.7191 - val_acc: 0.7200\n",
      "Epoch 88/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1423 - acc: 0.9856 - val_loss: 0.7895 - val_acc: 0.7000\n",
      "Epoch 89/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1358 - acc: 0.9856 - val_loss: 0.9621 - val_acc: 0.6600\n",
      "Epoch 90/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1301 - acc: 0.9856 - val_loss: 0.7885 - val_acc: 0.7200\n",
      "Epoch 91/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.1260 - acc: 0.9904 - val_loss: 0.8249 - val_acc: 0.6600\n",
      "Epoch 92/200\n",
      "209/209 [==============================] - 0s 259us/sample - loss: 0.1201 - acc: 0.9952 - val_loss: 0.7906 - val_acc: 0.7000\n",
      "Epoch 93/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.1204 - acc: 0.9952 - val_loss: 0.8696 - val_acc: 0.6800\n",
      "Epoch 94/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1231 - acc: 0.9904 - val_loss: 0.8088 - val_acc: 0.7000\n",
      "Epoch 95/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1169 - acc: 0.9904 - val_loss: 0.8209 - val_acc: 0.7000\n",
      "Epoch 96/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1153 - acc: 0.9904 - val_loss: 0.8327 - val_acc: 0.6800\n",
      "Epoch 97/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1158 - acc: 0.9952 - val_loss: 0.8231 - val_acc: 0.7000\n",
      "Epoch 98/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1158 - acc: 0.9809 - val_loss: 0.7686 - val_acc: 0.7400\n",
      "Epoch 99/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1213 - acc: 0.9856 - val_loss: 0.7931 - val_acc: 0.7200\n",
      "Epoch 100/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1131 - acc: 0.9952 - val_loss: 0.9232 - val_acc: 0.7000\n",
      "Epoch 101/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1186 - acc: 0.9856 - val_loss: 0.9283 - val_acc: 0.6800\n",
      "Epoch 102/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1184 - acc: 0.9952 - val_loss: 0.7444 - val_acc: 0.7200\n",
      "Epoch 103/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1285 - acc: 0.9809 - val_loss: 0.8934 - val_acc: 0.6800\n",
      "Epoch 104/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1130 - acc: 0.9952 - val_loss: 0.8680 - val_acc: 0.6600\n",
      "Epoch 105/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1101 - acc: 0.9761 - val_loss: 0.7666 - val_acc: 0.7200\n",
      "Epoch 106/200\n",
      "209/209 [==============================] - 0s 270us/sample - loss: 0.1196 - acc: 0.9904 - val_loss: 0.8015 - val_acc: 0.7200\n",
      "Epoch 107/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1085 - acc: 0.9952 - val_loss: 0.8369 - val_acc: 0.7000\n",
      "Epoch 108/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1026 - acc: 0.9952 - val_loss: 0.8794 - val_acc: 0.6600\n",
      "Epoch 109/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1055 - acc: 1.0000 - val_loss: 0.8079 - val_acc: 0.7200\n",
      "Epoch 110/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1034 - acc: 0.9952 - val_loss: 0.8617 - val_acc: 0.6800\n",
      "Epoch 111/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0996 - acc: 0.9952 - val_loss: 0.8580 - val_acc: 0.7000\n",
      "Epoch 112/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1044 - acc: 0.9952 - val_loss: 0.9156 - val_acc: 0.6600\n",
      "Epoch 113/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1035 - acc: 0.9952 - val_loss: 0.8169 - val_acc: 0.7200\n",
      "Epoch 114/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1165 - acc: 0.9809 - val_loss: 0.8366 - val_acc: 0.7200\n",
      "Epoch 115/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1213 - acc: 0.9809 - val_loss: 0.9921 - val_acc: 0.6800\n",
      "Epoch 116/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1035 - acc: 0.9904 - val_loss: 0.9320 - val_acc: 0.6800\n",
      "Epoch 117/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1121 - acc: 0.9856 - val_loss: 0.9323 - val_acc: 0.6800\n",
      "Epoch 118/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1209 - acc: 0.9761 - val_loss: 0.7984 - val_acc: 0.7200\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 325us/sample - loss: 0.1136 - acc: 0.9809 - val_loss: 0.9221 - val_acc: 0.6600\n",
      "Epoch 120/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.1172 - acc: 0.9856 - val_loss: 1.1605 - val_acc: 0.6000\n",
      "Epoch 121/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0970 - acc: 0.9952 - val_loss: 0.7988 - val_acc: 0.7200\n",
      "Epoch 122/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1426 - acc: 0.9569 - val_loss: 0.8728 - val_acc: 0.7200\n",
      "Epoch 123/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.1165 - acc: 0.9761 - val_loss: 1.3486 - val_acc: 0.5400\n",
      "Epoch 124/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.1243 - acc: 0.9809 - val_loss: 0.8618 - val_acc: 0.7000\n",
      "Epoch 125/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0902 - acc: 1.0000 - val_loss: 0.8883 - val_acc: 0.6800\n",
      "Epoch 126/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0861 - acc: 0.9952 - val_loss: 0.9146 - val_acc: 0.6600\n",
      "Epoch 127/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0965 - acc: 0.9952 - val_loss: 0.8219 - val_acc: 0.7200\n",
      "Epoch 128/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0919 - acc: 0.9952 - val_loss: 0.9498 - val_acc: 0.6800\n",
      "Epoch 129/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0843 - acc: 0.9952 - val_loss: 0.9394 - val_acc: 0.6800\n",
      "Epoch 130/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0822 - acc: 1.0000 - val_loss: 0.8666 - val_acc: 0.7200\n",
      "Epoch 131/200\n",
      "209/209 [==============================] - 0s 321us/sample - loss: 0.0847 - acc: 0.9952 - val_loss: 0.8951 - val_acc: 0.7200\n",
      "Epoch 132/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0873 - acc: 0.9952 - val_loss: 1.0097 - val_acc: 0.6600\n",
      "Epoch 133/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0872 - acc: 0.9952 - val_loss: 0.9927 - val_acc: 0.6600\n",
      "Epoch 134/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0907 - acc: 1.0000 - val_loss: 0.9569 - val_acc: 0.6600\n",
      "Epoch 135/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0820 - acc: 0.9952 - val_loss: 0.8585 - val_acc: 0.7400\n",
      "Epoch 136/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0857 - acc: 1.0000 - val_loss: 0.9805 - val_acc: 0.6800\n",
      "Epoch 137/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0800 - acc: 0.9952 - val_loss: 0.9603 - val_acc: 0.6800\n",
      "Epoch 138/200\n",
      "209/209 [==============================] - 0s 239us/sample - loss: 0.0772 - acc: 0.9952 - val_loss: 0.9443 - val_acc: 0.6600\n",
      "Epoch 139/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.0765 - acc: 0.9952 - val_loss: 0.8992 - val_acc: 0.7200\n",
      "Epoch 140/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0777 - acc: 0.9952 - val_loss: 0.9218 - val_acc: 0.6600\n",
      "Epoch 141/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0813 - acc: 0.9904 - val_loss: 1.1518 - val_acc: 0.6200\n",
      "Epoch 142/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.1010 - acc: 0.9904 - val_loss: 0.9225 - val_acc: 0.6600\n",
      "Epoch 143/200\n",
      "209/209 [==============================] - 0s 253us/sample - loss: 0.0761 - acc: 1.0000 - val_loss: 0.9451 - val_acc: 0.6600\n",
      "Epoch 144/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0724 - acc: 0.9952 - val_loss: 0.9512 - val_acc: 0.6600\n",
      "Epoch 145/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0770 - acc: 0.9952 - val_loss: 0.9177 - val_acc: 0.7200\n",
      "Epoch 146/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0754 - acc: 1.0000 - val_loss: 0.8866 - val_acc: 0.7200\n",
      "Epoch 147/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0803 - acc: 1.0000 - val_loss: 0.9454 - val_acc: 0.6800\n",
      "Epoch 148/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0898 - acc: 0.9952 - val_loss: 1.1260 - val_acc: 0.6400\n",
      "Epoch 149/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0824 - acc: 0.9904 - val_loss: 0.9826 - val_acc: 0.6600\n",
      "Epoch 150/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0700 - acc: 0.9952 - val_loss: 1.0156 - val_acc: 0.6800\n",
      "Epoch 151/200\n",
      "209/209 [==============================] - 0s 325us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.9019 - val_acc: 0.7200\n",
      "Epoch 152/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0721 - acc: 1.0000 - val_loss: 0.9820 - val_acc: 0.6600\n",
      "Epoch 153/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0756 - acc: 1.0000 - val_loss: 1.1280 - val_acc: 0.6400\n",
      "Epoch 154/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0883 - acc: 0.9952 - val_loss: 1.0076 - val_acc: 0.6600\n",
      "Epoch 155/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 0.9254 - val_acc: 0.7200\n",
      "Epoch 156/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0683 - acc: 1.0000 - val_loss: 0.9892 - val_acc: 0.6600\n",
      "Epoch 157/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0692 - acc: 1.0000 - val_loss: 1.0679 - val_acc: 0.6600\n",
      "Epoch 158/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0676 - acc: 1.0000 - val_loss: 0.9670 - val_acc: 0.6800\n",
      "Epoch 159/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.9311 - val_acc: 0.7200\n",
      "Epoch 160/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0679 - acc: 0.9952 - val_loss: 1.0084 - val_acc: 0.6800\n",
      "Epoch 161/200\n",
      "209/209 [==============================] - 0s 269us/sample - loss: 0.0632 - acc: 0.9952 - val_loss: 1.0431 - val_acc: 0.6800\n",
      "Epoch 162/200\n",
      "209/209 [==============================] - 0s 249us/sample - loss: 0.0647 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.6800\n",
      "Epoch 163/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0610 - acc: 1.0000 - val_loss: 1.0403 - val_acc: 0.6800\n",
      "Epoch 164/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0682 - acc: 0.9952 - val_loss: 0.9554 - val_acc: 0.7200\n",
      "Epoch 165/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.9779 - val_acc: 0.7200\n",
      "Epoch 166/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0605 - acc: 0.9952 - val_loss: 1.0279 - val_acc: 0.6800\n",
      "Epoch 167/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 1.0654 - val_acc: 0.6600\n",
      "Epoch 168/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0635 - acc: 0.9952 - val_loss: 0.9692 - val_acc: 0.6800\n",
      "Epoch 169/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0648 - acc: 1.0000 - val_loss: 0.9660 - val_acc: 0.7000\n",
      "Epoch 170/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0585 - acc: 0.9952 - val_loss: 1.0333 - val_acc: 0.6800\n",
      "Epoch 171/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.0604 - acc: 0.9952 - val_loss: 1.0824 - val_acc: 0.6600\n",
      "Epoch 172/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 1.0033 - val_acc: 0.6800\n",
      "Epoch 173/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0580 - acc: 0.9952 - val_loss: 1.0714 - val_acc: 0.6800\n",
      "Epoch 174/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 1.0247 - val_acc: 0.6800\n",
      "Epoch 175/200\n",
      "209/209 [==============================] - 0s 239us/sample - loss: 0.0642 - acc: 1.0000 - val_loss: 0.9801 - val_acc: 0.7200\n",
      "Epoch 176/200\n",
      "209/209 [==============================] - 0s 244us/sample - loss: 0.0606 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.7200\n",
      "Epoch 177/200\n",
      "209/209 [==============================] - 0s 254us/sample - loss: 0.0606 - acc: 0.9952 - val_loss: 1.0643 - val_acc: 0.6800\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0540 - acc: 0.9952 - val_loss: 1.0036 - val_acc: 0.6800\n",
      "Epoch 179/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 1.0286 - val_acc: 0.6800\n",
      "Epoch 180/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0529 - acc: 1.0000 - val_loss: 1.0095 - val_acc: 0.6800\n",
      "Epoch 181/200\n",
      "209/209 [==============================] - 0s 253us/sample - loss: 0.0563 - acc: 0.9952 - val_loss: 1.0364 - val_acc: 0.6800\n",
      "Epoch 182/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 1.0215 - val_acc: 0.6800\n",
      "Epoch 183/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 1.0390 - val_acc: 0.7000\n",
      "Epoch 184/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0537 - acc: 1.0000 - val_loss: 1.1169 - val_acc: 0.6600\n",
      "Epoch 185/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0568 - acc: 1.0000 - val_loss: 0.9639 - val_acc: 0.7200\n",
      "Epoch 186/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0590 - acc: 0.9952 - val_loss: 1.0765 - val_acc: 0.6800\n",
      "Epoch 187/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 1.1170 - val_acc: 0.6600\n",
      "Epoch 188/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0552 - acc: 0.9952 - val_loss: 1.0697 - val_acc: 0.6800\n",
      "Epoch 189/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 1.0049 - val_acc: 0.7200\n",
      "Epoch 190/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 1.0076 - val_acc: 0.7200\n",
      "Epoch 191/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 1.1187 - val_acc: 0.6600\n",
      "Epoch 192/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 1.0372 - val_acc: 0.6800\n",
      "Epoch 193/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 1.0316 - val_acc: 0.6800\n",
      "Epoch 194/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0507 - acc: 0.9952 - val_loss: 1.1116 - val_acc: 0.6600\n",
      "Epoch 195/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.0485 - acc: 1.0000 - val_loss: 1.0488 - val_acc: 0.6800\n",
      "Epoch 196/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 1.0694 - val_acc: 0.7000\n",
      "Epoch 197/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 1.1237 - val_acc: 0.6600\n",
      "Epoch 198/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.0530 - acc: 1.0000 - val_loss: 0.9983 - val_acc: 0.7200\n",
      "Epoch 199/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0513 - acc: 1.0000 - val_loss: 1.0192 - val_acc: 0.7000\n",
      "Epoch 200/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0565 - acc: 0.9952 - val_loss: 1.1514 - val_acc: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c21482d1d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flatten, y_train, epochs=100, validation_data=(X_test_flatten, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 180us/sample - loss: 1.1514 - acc: 0.6600\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_flatten, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Test score : 1.15\n",
      "Test accuracy : 0.66\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(\"Test score : {:.2f}\".format(score[0]))\n",
    "print(\"Test accuracy : {:.2f}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_flatten)\n",
    "np.sum((y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 hidden layer Logitstic Regression model - 2 layers\n",
    "\n",
    "<img src=\"LogReg_2layers.png\" style=\"width:650px;height:400px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(7, input_shape=(12288,)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 7)                 86023     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 8         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 86,031\n",
      "Trainable params: 86,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 209 samples, validate on 50 samples\n",
      "Epoch 1/200\n",
      "209/209 [==============================] - 0s 1ms/sample - loss: 1.2588 - acc: 0.5885 - val_loss: 2.6715 - val_acc: 0.3400\n",
      "Epoch 2/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 1.0643 - acc: 0.5742 - val_loss: 0.5630 - val_acc: 0.7600\n",
      "Epoch 3/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.7417 - acc: 0.6411 - val_loss: 0.7809 - val_acc: 0.4000\n",
      "Epoch 4/200\n",
      "209/209 [==============================] - 0s 317us/sample - loss: 0.6099 - acc: 0.6699 - val_loss: 0.8875 - val_acc: 0.3400\n",
      "Epoch 5/200\n",
      "209/209 [==============================] - 0s 321us/sample - loss: 0.5660 - acc: 0.7129 - val_loss: 0.7018 - val_acc: 0.5200\n",
      "Epoch 6/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.5368 - acc: 0.7081 - val_loss: 0.5697 - val_acc: 0.7200\n",
      "Epoch 7/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.5501 - acc: 0.7225 - val_loss: 0.5391 - val_acc: 0.7800\n",
      "Epoch 8/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.5166 - acc: 0.7560 - val_loss: 0.6688 - val_acc: 0.5400\n",
      "Epoch 9/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.4990 - acc: 0.7751 - val_loss: 0.7170 - val_acc: 0.5400\n",
      "Epoch 10/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.4690 - acc: 0.8086 - val_loss: 0.5393 - val_acc: 0.7800\n",
      "Epoch 11/200\n",
      "209/209 [==============================] - 0s 349us/sample - loss: 0.5280 - acc: 0.7368 - val_loss: 0.6538 - val_acc: 0.5600\n",
      "Epoch 12/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.4957 - acc: 0.7703 - val_loss: 0.6857 - val_acc: 0.5400\n",
      "Epoch 13/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.4630 - acc: 0.7847 - val_loss: 0.5453 - val_acc: 0.7400\n",
      "Epoch 14/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.4648 - acc: 0.7560 - val_loss: 0.5295 - val_acc: 0.7400\n",
      "Epoch 15/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.4361 - acc: 0.7943 - val_loss: 0.4883 - val_acc: 0.8200\n",
      "Epoch 16/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.4165 - acc: 0.8660 - val_loss: 0.6665 - val_acc: 0.5800\n",
      "Epoch 17/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.3940 - acc: 0.8660 - val_loss: 0.6918 - val_acc: 0.6000\n",
      "Epoch 18/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.4125 - acc: 0.8230 - val_loss: 0.4852 - val_acc: 0.8000\n",
      "Epoch 19/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.4540 - acc: 0.7799 - val_loss: 0.4879 - val_acc: 0.8200\n",
      "Epoch 20/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.3970 - acc: 0.8373 - val_loss: 0.6063 - val_acc: 0.6600\n",
      "Epoch 21/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.3670 - acc: 0.8804 - val_loss: 0.7370 - val_acc: 0.5400\n",
      "Epoch 22/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.3781 - acc: 0.8278 - val_loss: 0.4800 - val_acc: 0.8200\n",
      "Epoch 23/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.3522 - acc: 0.8708 - val_loss: 0.5183 - val_acc: 0.7800\n",
      "Epoch 24/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.3589 - acc: 0.8804 - val_loss: 0.5039 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.3477 - acc: 0.9091 - val_loss: 0.5031 - val_acc: 0.7800\n",
      "Epoch 26/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.3538 - acc: 0.8565 - val_loss: 0.5790 - val_acc: 0.7400\n",
      "Epoch 27/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.3293 - acc: 0.9139 - val_loss: 0.6697 - val_acc: 0.6800\n",
      "Epoch 28/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.3116 - acc: 0.9091 - val_loss: 0.6633 - val_acc: 0.6800\n",
      "Epoch 29/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2989 - acc: 0.9139 - val_loss: 0.5472 - val_acc: 0.7400\n",
      "Epoch 30/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.3010 - acc: 0.9234 - val_loss: 0.5292 - val_acc: 0.7400\n",
      "Epoch 31/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.3012 - acc: 0.9091 - val_loss: 0.6177 - val_acc: 0.7200\n",
      "Epoch 32/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2940 - acc: 0.8995 - val_loss: 0.5641 - val_acc: 0.7600\n",
      "Epoch 33/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2849 - acc: 0.9139 - val_loss: 0.6296 - val_acc: 0.7200\n",
      "Epoch 34/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2712 - acc: 0.9282 - val_loss: 0.5152 - val_acc: 0.7600\n",
      "Epoch 35/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.3021 - acc: 0.8995 - val_loss: 0.5159 - val_acc: 0.7400\n",
      "Epoch 36/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2737 - acc: 0.9234 - val_loss: 0.5873 - val_acc: 0.7600\n",
      "Epoch 37/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2559 - acc: 0.9474 - val_loss: 0.6570 - val_acc: 0.7200\n",
      "Epoch 38/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.2961 - acc: 0.9091 - val_loss: 0.7900 - val_acc: 0.6000\n",
      "Epoch 39/200\n",
      "209/209 [==============================] - 0s 321us/sample - loss: 0.2399 - acc: 0.9474 - val_loss: 0.5893 - val_acc: 0.7600\n",
      "Epoch 40/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.2483 - acc: 0.9378 - val_loss: 0.5559 - val_acc: 0.7400\n",
      "Epoch 41/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2487 - acc: 0.9378 - val_loss: 0.6362 - val_acc: 0.7800\n",
      "Epoch 42/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2493 - acc: 0.9378 - val_loss: 0.5301 - val_acc: 0.7600\n",
      "Epoch 43/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2396 - acc: 0.9378 - val_loss: 0.6758 - val_acc: 0.7600\n",
      "Epoch 44/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.2286 - acc: 0.9713 - val_loss: 0.5614 - val_acc: 0.7200\n",
      "Epoch 45/200\n",
      "209/209 [==============================] - 0s 273us/sample - loss: 0.2413 - acc: 0.9187 - val_loss: 0.5486 - val_acc: 0.7400\n",
      "Epoch 46/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.2238 - acc: 0.9234 - val_loss: 0.5943 - val_acc: 0.7400\n",
      "Epoch 47/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2287 - acc: 0.9522 - val_loss: 0.6858 - val_acc: 0.7200\n",
      "Epoch 48/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2036 - acc: 0.9665 - val_loss: 0.6279 - val_acc: 0.7800\n",
      "Epoch 49/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.2008 - acc: 0.9665 - val_loss: 0.6963 - val_acc: 0.7400\n",
      "Epoch 50/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2021 - acc: 0.9474 - val_loss: 0.6425 - val_acc: 0.7600\n",
      "Epoch 51/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1930 - acc: 0.9761 - val_loss: 0.6633 - val_acc: 0.7400\n",
      "Epoch 52/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.1968 - acc: 0.9713 - val_loss: 0.8245 - val_acc: 0.6000\n",
      "Epoch 53/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1942 - acc: 0.9665 - val_loss: 0.7675 - val_acc: 0.7000\n",
      "Epoch 54/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1918 - acc: 0.9713 - val_loss: 0.6586 - val_acc: 0.7800\n",
      "Epoch 55/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1824 - acc: 0.9665 - val_loss: 0.6456 - val_acc: 0.7400\n",
      "Epoch 56/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1849 - acc: 0.9713 - val_loss: 0.6532 - val_acc: 0.7400\n",
      "Epoch 57/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1706 - acc: 0.9809 - val_loss: 0.7338 - val_acc: 0.7200\n",
      "Epoch 58/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.1734 - acc: 0.9665 - val_loss: 0.6057 - val_acc: 0.7200\n",
      "Epoch 59/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1776 - acc: 0.9665 - val_loss: 0.6054 - val_acc: 0.7200\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 273us/sample - loss: 0.1783 - acc: 0.9665 - val_loss: 0.5913 - val_acc: 0.7200\n",
      "Epoch 61/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1987 - acc: 0.9713 - val_loss: 0.5749 - val_acc: 0.7600\n",
      "Epoch 62/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.2075 - acc: 0.9330 - val_loss: 0.5985 - val_acc: 0.7200\n",
      "Epoch 63/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1990 - acc: 0.9426 - val_loss: 0.6664 - val_acc: 0.7400\n",
      "Epoch 64/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.1928 - acc: 0.9426 - val_loss: 0.7420 - val_acc: 0.7200\n",
      "Epoch 65/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1798 - acc: 0.9522 - val_loss: 0.7203 - val_acc: 0.7000\n",
      "Epoch 66/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.1656 - acc: 0.9665 - val_loss: 0.7362 - val_acc: 0.7200\n",
      "Epoch 67/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1621 - acc: 0.9761 - val_loss: 0.7259 - val_acc: 0.7000\n",
      "Epoch 68/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1716 - acc: 0.9713 - val_loss: 0.9525 - val_acc: 0.6000\n",
      "Epoch 69/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.1637 - acc: 0.9617 - val_loss: 1.0981 - val_acc: 0.5200\n",
      "Epoch 70/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.1865 - acc: 0.9187 - val_loss: 1.0242 - val_acc: 0.5600\n",
      "Epoch 71/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1783 - acc: 0.9522 - val_loss: 0.8776 - val_acc: 0.7000\n",
      "Epoch 72/200\n",
      "209/209 [==============================] - 0s 283us/sample - loss: 0.1362 - acc: 0.9809 - val_loss: 0.7250 - val_acc: 0.7400\n",
      "Epoch 73/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1326 - acc: 0.9761 - val_loss: 0.7245 - val_acc: 0.7400\n",
      "Epoch 74/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.1232 - acc: 0.9809 - val_loss: 0.7934 - val_acc: 0.7200\n",
      "Epoch 75/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1256 - acc: 0.9856 - val_loss: 0.7138 - val_acc: 0.7400\n",
      "Epoch 76/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1239 - acc: 0.9856 - val_loss: 0.7453 - val_acc: 0.7400\n",
      "Epoch 77/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.1183 - acc: 0.9904 - val_loss: 0.8319 - val_acc: 0.7200\n",
      "Epoch 78/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1215 - acc: 0.9761 - val_loss: 0.8711 - val_acc: 0.7000\n",
      "Epoch 79/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1251 - acc: 0.9761 - val_loss: 0.7717 - val_acc: 0.7200\n",
      "Epoch 80/200\n",
      "209/209 [==============================] - 0s 296us/sample - loss: 0.1518 - acc: 0.9617 - val_loss: 0.7145 - val_acc: 0.7400\n",
      "Epoch 81/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.1213 - acc: 0.9856 - val_loss: 0.6945 - val_acc: 0.7200\n",
      "Epoch 82/200\n",
      "209/209 [==============================] - 0s 325us/sample - loss: 0.1359 - acc: 0.9761 - val_loss: 0.6944 - val_acc: 0.7200\n",
      "Epoch 83/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1392 - acc: 0.9713 - val_loss: 0.7657 - val_acc: 0.7200\n",
      "Epoch 84/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1189 - acc: 0.9856 - val_loss: 0.8836 - val_acc: 0.7000\n",
      "Epoch 85/200\n",
      "209/209 [==============================] - 0s 283us/sample - loss: 0.0978 - acc: 0.9952 - val_loss: 0.7404 - val_acc: 0.7400\n",
      "Epoch 86/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.1124 - acc: 0.9952 - val_loss: 0.7124 - val_acc: 0.7200\n",
      "Epoch 87/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.1226 - acc: 0.9856 - val_loss: 0.7403 - val_acc: 0.7200\n",
      "Epoch 88/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.1349 - acc: 0.9474 - val_loss: 1.0091 - val_acc: 0.5800\n",
      "Epoch 89/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.1219 - acc: 0.9665 - val_loss: 1.0722 - val_acc: 0.5800\n",
      "Epoch 90/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.1154 - acc: 0.9856 - val_loss: 0.7900 - val_acc: 0.7200\n",
      "Epoch 91/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.1005 - acc: 0.9904 - val_loss: 0.8462 - val_acc: 0.7200\n",
      "Epoch 92/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0995 - acc: 0.9856 - val_loss: 0.7428 - val_acc: 0.7400\n",
      "Epoch 93/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0940 - acc: 0.9904 - val_loss: 0.7886 - val_acc: 0.7200\n",
      "Epoch 94/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0905 - acc: 0.9952 - val_loss: 0.8446 - val_acc: 0.7200\n",
      "Epoch 95/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0875 - acc: 0.9904 - val_loss: 0.8178 - val_acc: 0.7200\n",
      "Epoch 96/200\n",
      "209/209 [==============================] - 0s 320us/sample - loss: 0.0856 - acc: 0.9952 - val_loss: 0.8824 - val_acc: 0.7400\n",
      "Epoch 97/200\n",
      "209/209 [==============================] - 0s 378us/sample - loss: 0.0827 - acc: 0.9952 - val_loss: 0.8623 - val_acc: 0.7400\n",
      "Epoch 98/200\n",
      "209/209 [==============================] - 0s 373us/sample - loss: 0.0824 - acc: 0.9952 - val_loss: 0.8941 - val_acc: 0.6800\n",
      "Epoch 99/200\n",
      "209/209 [==============================] - 0s 349us/sample - loss: 0.0855 - acc: 1.0000 - val_loss: 0.8517 - val_acc: 0.7200\n",
      "Epoch 100/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0857 - acc: 0.9952 - val_loss: 0.8490 - val_acc: 0.7400\n",
      "Epoch 101/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.7200\n",
      "Epoch 102/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.0812 - acc: 0.9952 - val_loss: 1.0074 - val_acc: 0.6600\n",
      "Epoch 103/200\n",
      "209/209 [==============================] - 0s 288us/sample - loss: 0.0868 - acc: 0.9952 - val_loss: 0.9697 - val_acc: 0.6800\n",
      "Epoch 104/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0749 - acc: 0.9952 - val_loss: 0.8843 - val_acc: 0.7200\n",
      "Epoch 105/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0751 - acc: 0.9952 - val_loss: 0.9511 - val_acc: 0.7000\n",
      "Epoch 106/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.9631 - val_acc: 0.6800\n",
      "Epoch 107/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0738 - acc: 1.0000 - val_loss: 1.0362 - val_acc: 0.6600\n",
      "Epoch 108/200\n",
      "209/209 [==============================] - 0s 263us/sample - loss: 0.0763 - acc: 0.9952 - val_loss: 0.9120 - val_acc: 0.7400\n",
      "Epoch 109/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0680 - acc: 0.9952 - val_loss: 0.9873 - val_acc: 0.6800\n",
      "Epoch 110/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0702 - acc: 1.0000 - val_loss: 0.9596 - val_acc: 0.6800\n",
      "Epoch 111/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0684 - acc: 0.9952 - val_loss: 0.9072 - val_acc: 0.7200\n",
      "Epoch 112/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0655 - acc: 0.9952 - val_loss: 0.9246 - val_acc: 0.7200\n",
      "Epoch 113/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.7200\n",
      "Epoch 114/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0696 - acc: 0.9952 - val_loss: 0.9485 - val_acc: 0.7400\n",
      "Epoch 115/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0630 - acc: 1.0000 - val_loss: 1.0351 - val_acc: 0.6800\n",
      "Epoch 116/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0664 - acc: 1.0000 - val_loss: 1.0814 - val_acc: 0.6600\n",
      "Epoch 117/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0690 - acc: 0.9952 - val_loss: 0.9471 - val_acc: 0.7400\n",
      "Epoch 118/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0599 - acc: 1.0000 - val_loss: 0.9231 - val_acc: 0.7200\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 273us/sample - loss: 0.0584 - acc: 0.9952 - val_loss: 0.9305 - val_acc: 0.7200\n",
      "Epoch 120/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0623 - acc: 0.9952 - val_loss: 1.0223 - val_acc: 0.6800\n",
      "Epoch 121/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0596 - acc: 0.9952 - val_loss: 0.9935 - val_acc: 0.7000\n",
      "Epoch 122/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0554 - acc: 1.0000 - val_loss: 1.0759 - val_acc: 0.6800\n",
      "Epoch 123/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0608 - acc: 0.9952 - val_loss: 0.9416 - val_acc: 0.7200\n",
      "Epoch 124/200\n",
      "209/209 [==============================] - 0s 315us/sample - loss: 0.0534 - acc: 1.0000 - val_loss: 1.1150 - val_acc: 0.6600\n",
      "Epoch 125/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0555 - acc: 1.0000 - val_loss: 0.9559 - val_acc: 0.7400\n",
      "Epoch 126/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 1.0144 - val_acc: 0.7000\n",
      "Epoch 127/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.8940 - val_acc: 0.7400\n",
      "Epoch 128/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0592 - acc: 1.0000 - val_loss: 0.9699 - val_acc: 0.7200\n",
      "Epoch 129/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0549 - acc: 0.9952 - val_loss: 1.1315 - val_acc: 0.6600\n",
      "Epoch 130/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0495 - acc: 1.0000 - val_loss: 0.9763 - val_acc: 0.7200\n",
      "Epoch 131/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.9584 - val_acc: 0.7200\n",
      "Epoch 132/200\n",
      "209/209 [==============================] - 0s 362us/sample - loss: 0.0509 - acc: 1.0000 - val_loss: 0.9641 - val_acc: 0.7200\n",
      "Epoch 133/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 1.0464 - val_acc: 0.7000\n",
      "Epoch 134/200\n",
      "209/209 [==============================] - 0s 283us/sample - loss: 0.0466 - acc: 0.9952 - val_loss: 1.0281 - val_acc: 0.7200\n",
      "Epoch 135/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0480 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.7200\n",
      "Epoch 136/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0533 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.7000\n",
      "Epoch 137/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0493 - acc: 0.9952 - val_loss: 1.1856 - val_acc: 0.6800\n",
      "Epoch 138/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.7200\n",
      "Epoch 139/200\n",
      "209/209 [==============================] - 0s 321us/sample - loss: 0.0462 - acc: 1.0000 - val_loss: 0.9738 - val_acc: 0.7200\n",
      "Epoch 140/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0450 - acc: 0.9952 - val_loss: 1.1093 - val_acc: 0.6800\n",
      "Epoch 141/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 0.9715 - val_acc: 0.7200\n",
      "Epoch 142/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0549 - acc: 1.0000 - val_loss: 0.9478 - val_acc: 0.7200\n",
      "Epoch 143/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0490 - acc: 0.9952 - val_loss: 1.0391 - val_acc: 0.7400\n",
      "Epoch 144/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 1.1345 - val_acc: 0.6600\n",
      "Epoch 145/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0432 - acc: 0.9952 - val_loss: 1.1105 - val_acc: 0.6800\n",
      "Epoch 146/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0420 - acc: 0.9952 - val_loss: 1.2393 - val_acc: 0.6600\n",
      "Epoch 147/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 1.0359 - val_acc: 0.7200\n",
      "Epoch 148/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 1.0999 - val_acc: 0.7000\n",
      "Epoch 149/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0409 - acc: 0.9952 - val_loss: 1.1985 - val_acc: 0.6600\n",
      "Epoch 150/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0396 - acc: 0.9952 - val_loss: 1.1627 - val_acc: 0.6800\n",
      "Epoch 151/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 1.0429 - val_acc: 0.7200\n",
      "Epoch 152/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0388 - acc: 0.9952 - val_loss: 1.0624 - val_acc: 0.7200\n",
      "Epoch 153/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 1.1561 - val_acc: 0.7000\n",
      "Epoch 154/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 1.0679 - val_acc: 0.7200\n",
      "Epoch 155/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 1.0596 - val_acc: 0.7200\n",
      "Epoch 156/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0448 - acc: 0.9952 - val_loss: 1.1788 - val_acc: 0.6800\n",
      "Epoch 157/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 1.2624 - val_acc: 0.6600\n",
      "Epoch 158/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 1.1069 - val_acc: 0.7200\n",
      "Epoch 159/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 1.0383 - val_acc: 0.7200\n",
      "Epoch 160/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 1.1872 - val_acc: 0.6800\n",
      "Epoch 161/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 1.1170 - val_acc: 0.7000\n",
      "Epoch 162/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 1.1128 - val_acc: 0.7200\n",
      "Epoch 163/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 1.2120 - val_acc: 0.6800\n",
      "Epoch 164/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 1.0690 - val_acc: 0.7200\n",
      "Epoch 165/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 1.1844 - val_acc: 0.7000\n",
      "Epoch 166/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 1.2037 - val_acc: 0.6800\n",
      "Epoch 167/200\n",
      "209/209 [==============================] - 0s 316us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.7200\n",
      "Epoch 168/200\n",
      "209/209 [==============================] - 0s 335us/sample - loss: 0.0302 - acc: 1.0000 - val_loss: 1.1611 - val_acc: 0.7000\n",
      "Epoch 169/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 1.1568 - val_acc: 0.7000\n",
      "Epoch 170/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 1.2200 - val_acc: 0.6800\n",
      "Epoch 171/200\n",
      "209/209 [==============================] - 0s 275us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 1.2372 - val_acc: 0.6800\n",
      "Epoch 172/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 1.1578 - val_acc: 0.7000\n",
      "Epoch 173/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 1.1531 - val_acc: 0.7000\n",
      "Epoch 174/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 1.1208 - val_acc: 0.7200\n",
      "Epoch 175/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0336 - acc: 1.0000 - val_loss: 1.2569 - val_acc: 0.7000\n",
      "Epoch 176/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 1.1949 - val_acc: 0.7000\n",
      "Epoch 177/200\n",
      "209/209 [==============================] - 0s 277us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 1.1259 - val_acc: 0.7200\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 1.1627 - val_acc: 0.7000\n",
      "Epoch 179/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 1.2069 - val_acc: 0.7000\n",
      "Epoch 180/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 1.1491 - val_acc: 0.7400\n",
      "Epoch 181/200\n",
      "209/209 [==============================] - 0s 297us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 1.2895 - val_acc: 0.7000\n",
      "Epoch 182/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 1.1745 - val_acc: 0.7000\n",
      "Epoch 183/200\n",
      "209/209 [==============================] - 0s 335us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 1.1372 - val_acc: 0.7200\n",
      "Epoch 184/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 1.2771 - val_acc: 0.7000\n",
      "Epoch 185/200\n",
      "209/209 [==============================] - 0s 311us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 1.3060 - val_acc: 0.7000\n",
      "Epoch 186/200\n",
      "209/209 [==============================] - 0s 306us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 1.1187 - val_acc: 0.7200\n",
      "Epoch 187/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 1.3558 - val_acc: 0.6800\n",
      "Epoch 188/200\n",
      "209/209 [==============================] - 0s 342us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 1.1947 - val_acc: 0.7000\n",
      "Epoch 189/200\n",
      "209/209 [==============================] - 0s 301us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 1.3027 - val_acc: 0.7000\n",
      "Epoch 190/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 1.1954 - val_acc: 0.7000\n",
      "Epoch 191/200\n",
      "209/209 [==============================] - 0s 258us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 1.2747 - val_acc: 0.7000\n",
      "Epoch 192/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 1.3909 - val_acc: 0.6800\n",
      "Epoch 193/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 1.1851 - val_acc: 0.7200\n",
      "Epoch 194/200\n",
      "209/209 [==============================] - 0s 268us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 1.1697 - val_acc: 0.7200\n",
      "Epoch 195/200\n",
      "209/209 [==============================] - 0s 278us/sample - loss: 0.0306 - acc: 0.9952 - val_loss: 1.2662 - val_acc: 0.7000\n",
      "Epoch 196/200\n",
      "209/209 [==============================] - 0s 287us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 1.2818 - val_acc: 0.7000\n",
      "Epoch 197/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 1.3008 - val_acc: 0.7000\n",
      "Epoch 198/200\n",
      "209/209 [==============================] - 0s 282us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 1.2415 - val_acc: 0.7000\n",
      "Epoch 199/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 1.4318 - val_acc: 0.6800\n",
      "Epoch 200/200\n",
      "209/209 [==============================] - 0s 292us/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 1.2068 - val_acc: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c314e8f470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_flatten, y_train, epochs=100, validation_data=(X_test_flatten, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 220us/sample - loss: 1.2068 - acc: 0.7400\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_flatten, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "Test score : 1.21\n",
      "Test accuracy : 0.74\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(\"Test score : {:.2f}\".format(score[0]))\n",
    "print(\"Test accuracy : {:.2f}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
