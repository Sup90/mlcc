{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Simple Text - Alice in Wonderland\n",
    "\n",
    "- 161793 글자로 이루어진 text 를 10 글자 단위로 잘라 input data 를 만들고 뒤 따라오는 글자를 label data 로 만들어 supervised learning  \n",
    "\n",
    "      ex) “alice lear”  - “n” \n",
    "           “lice learn”  - “e”\n",
    "           “ice learne” – “d”  \n",
    "       \n",
    "- Validation 은 seed 가 되는 10 글자 data 를 주고 이어서 만드는 100 글자 문장이 의미 있는지 여부 육안으로 검토\n",
    "\n",
    "      ex) seed : “alice look”  \n",
    "          output : “alice looked at the mouse was a trite than she ..”   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice in Wonderland Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "r = urlopen(\"http://www.gutenberg.org/files/11/11.txt\")\n",
    "fin= r.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\\r\\n\",\n",
       " b'\\r\\n',\n",
       " b'This eBook is for the use of anyone anywhere at no cost and with\\r\\n',\n",
       " b'almost no restrictions whatsoever.  You may copy it, give it away or\\r\\n',\n",
       " b're-use it under the terms of the Project Gutenberg License included\\r\\n',\n",
       " b'with this eBook or online at www.gutenberg.org\\r\\n',\n",
       " b'\\r\\n',\n",
       " b'\\r\\n',\n",
       " b\"Title: Alice's Adventures in Wonderland\\r\\n\",\n",
       " b'\\r\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "white space 제거, 소문자 통일, binary 를 string type 으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lookup table 작성\n",
    "\n",
    "- text 중에 포함된 character 들을 이용하여 charactet-to-index, index-to-character 변환 table 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 및 label data 작성\n",
    "\n",
    "- 10 개의 연속된 character sequence 를 input 으로 하고, 다음에 오는 character 를 label 로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161793 161793\n"
     ]
    }
   ],
   "source": [
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_data = []\n",
    "label_data = []\n",
    "\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_data.append(text[i:i + SEQLEN])\n",
    "    label_data.append(text[i+SEQLEN])\n",
    "    \n",
    "print(len(input_data), len(label_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project gu',\n",
       " 'roject gut',\n",
       " 'oject gute',\n",
       " 'ject guten',\n",
       " 'ect gutenb',\n",
       " 'ct gutenbe',\n",
       " 't gutenber',\n",
       " ' gutenberg',\n",
       " \"gutenberg'\",\n",
       " \"utenberg's\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'e', 'n', 'b', 'e', 'r', 'g', \"'\", 's', ' ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vectorize input data\n",
    "\n",
    "\n",
    "input data 의 shape : (data_size, times_step, features)  \n",
    "\n",
    "output data 의 shape : (data_size, features)\n",
    "\n",
    "**One-hot encodeing** \n",
    "\n",
    "10 X 57\n",
    "\n",
    "'project gu' ==>  char2index['p'] : 36,  char2index['r'] : 45, char2index['o'] : 49\n",
    "\n",
    "p: [0., 0., 0,,,,,., 0., 0., 0.,0., 0., 0., 0., 1., 0., 0., 0., 0., ,,,,,,,,,,,,,., 0., 0., 0., 0.]  \n",
    "r: [0., 0., 0.,.,,,,,0., 0., 0., 0.,0., 0., 0., 0., ,,., 0., 0., 1., 0., ,,,,,,,,,,,,,., 0., 0., 0.]  \n",
    "0: [0., 0., 0.,.,,,,,0.,0.,0., 0,,,,,,,, 0., 0., 0. 0., 0., 0., 1., 0., ,,,,,,,,,,,,,., 0., 0., 0.]\n",
    "\n",
    "label ==>  char2index['t'] : 1   \n",
    "\n",
    "1X57\n",
    "\n",
    "t: [0., 1., 0.,.,,,,,0.,0.,0., 0,,,,,,,, 0., 0., 0. 0., 0., 0., ., 0., ,,,,,,,,,,,,,., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161793, 10, 57) (161793, 57)\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((len(input_data), SEQLEN, nb_chars))\n",
    "y = np.zeros((len(label_data), nb_chars))\n",
    "\n",
    "for i, input_chars in enumerate(input_data):\n",
    "    for j, ch in enumerate(input_chars):\n",
    "        X[i, j, char2index[ch]] = 1              \n",
    "    y[i, char2index[label_data[i]]] = 1\n",
    "    \n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(256, input_shape=(SEQLEN, nb_chars)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trimu\\Miniconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "161793/161793 [==============================] - 16s 98us/sample - loss: 2.3698\n",
      "Epoch 2/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 2.1254\n",
      "Epoch 3/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 2.0695\n",
      "Epoch 4/20\n",
      "161793/161793 [==============================] - 13s 83us/sample - loss: 2.0228\n",
      "Epoch 5/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 1.9798\n",
      "Epoch 6/20\n",
      "161793/161793 [==============================] - 15s 90us/sample - loss: 1.9391s - loss: 1.\n",
      "Epoch 7/20\n",
      "161793/161793 [==============================] - 14s 86us/sample - loss: 1.8977\n",
      "Epoch 8/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 1.8551\n",
      "Epoch 9/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 1.8207\n",
      "Epoch 10/20\n",
      "161793/161793 [==============================] - 14s 84us/sample - loss: 1.7857\n",
      "Epoch 11/20\n",
      "161793/161793 [==============================] - 15s 93us/sample - loss: 1.7607\n",
      "Epoch 12/20\n",
      "161793/161793 [==============================] - 14s 89us/sample - loss: 1.7211\n",
      "Epoch 13/20\n",
      "161793/161793 [==============================] - 14s 89us/sample - loss: 1.7105\n",
      "Epoch 14/20\n",
      "161793/161793 [==============================] - 15s 93us/sample - loss: 1.6751\n",
      "Epoch 15/20\n",
      "161793/161793 [==============================] - 14s 89us/sample - loss: 1.6593\n",
      "Epoch 16/20\n",
      "161793/161793 [==============================] - 15s 90us/sample - loss: 1.6258\n",
      "Epoch 17/20\n",
      "161793/161793 [==============================] - 15s 92us/sample - loss: 1.6081\n",
      "Epoch 18/20\n",
      "161793/161793 [==============================] - 15s 93us/sample - loss: 1.5875\n",
      "Epoch 19/20\n",
      "161793/161793 [==============================] - 15s 92us/sample - loss: 1.5766\n",
      "Epoch 20/20\n",
      "161793/161793 [==============================] - 15s 90us/sample - loss: 1.5523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de006a4f98>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed 로부터 의미있는 문장 생성하는지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2char[np.argmax(model.predict(X[0:1, :]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = np.zeros((1, 10, 57))\n",
    "\n",
    "for i, ch in enumerate(\"what is th\"):\n",
    "    Xtest[0, i, char2index[ch]] = 1\n",
    "\n",
    "pred = model.predict(Xtest)          # next character\n",
    "index2char[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating from seed :  e to measu\n"
     ]
    }
   ],
   "source": [
    "# select ramdom seed words\n",
    "test_idx = np.random.randint(len(input_data))\n",
    "test_chars = input_data[test_idx]\n",
    "    \n",
    "print(\"Generating from seed : \", test_chars, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the door as it was good all the rabbit have to herself, 'i con't got the d"
     ]
    }
   ],
   "source": [
    "# generate sentence from the seed words\n",
    "for _ in range(1000):\n",
    "    # one-hot encoding (10 X 57)\n",
    "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "\n",
    "    for i, ch in enumerate(test_chars):\n",
    "        Xtest[0, i, char2index[ch]] = 1\n",
    "\n",
    "    pred = model.predict(Xtest)      # next character\n",
    "\n",
    "    ypred_ch = index2char[np.argmax(pred)]\n",
    "\n",
    "    print(ypred_ch, end=\"\")\n",
    "    #shift one character\n",
    "    test_chars = test_chars[1:] + ypred_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
